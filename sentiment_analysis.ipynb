{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package wordnet to /Users/rong/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/rong/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "from modules import scraper\n",
    "\n",
    "import pandas as pd\n",
    "# Sklearn libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import learning_curve, cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import *\n",
    "# download required resources\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentiment_analysis(scraper.hotel_scraper):\n",
    "    \n",
    "    def gen_df(self, filename):\n",
    "        path = self.get_datadir() + filename\n",
    "        df = self.load_csv(path)\n",
    "        return df\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        sw = stopwords.words('English')\n",
    "        stemmer = porter.PorterStemmer()\n",
    "        text = re.sub(r'[^A-Za-z ]', '', text.lower())\n",
    "        text = ' '.join([stemmer.stem(r) for r in text.split() if r not in sw])\n",
    "        return text\n",
    "    \n",
    "    def data_preprocessing(self):\n",
    "        df = self.gen_df('review_data.csv')\n",
    "        df = df[['Reviews', 'Ratings']] \n",
    "        df['Reviews'] = df['Reviews'].apply(self.clean_text)\n",
    "        df['Ratings'] = df['Ratings'].apply(lambda x: 1 if x>=4 else 0)\n",
    "        return df\n",
    "    \n",
    "    def data_preparation(self, model_name):\n",
    "        df = self.data_preprocessing()\n",
    "        if model_name == 'TF-IDF':\n",
    "            X = df['Reviews']\n",
    "            y = df['Ratings']\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "            tvec = TfidfVectorizer(max_features=10000,ngram_range=(1, 5))\n",
    "            tvec.fit(X_train)\n",
    "            Xtrain_tfidf = tvec.transform(X_train)\n",
    "            Xtest_tfidf = tvec.transform(X_test).toarray()\n",
    "            return Xtrain_tfidf, Xtest_tfidf, y_train, y_test\n",
    "        elif model_name == 'LSTM':\n",
    "            X, y = (df['Reviews'].values, df['Ratings'].values)\n",
    "            tk = Tokenizer(num_words = 10000, lower=True)\n",
    "            tk.fit_on_texts(X)\n",
    "            X_seq = tk.texts_to_sequences(X)\n",
    "            X_pad = pad_sequences(X_seq, maxlen=100, padding='post')\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size = 0.3, random_state = 101)\n",
    "            return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def build_model(self, model_name):\n",
    "        X_train, X_test, y_train, y_test = self.data_preparation(model_name)\n",
    "        if model_name == 'TF-IDF':\n",
    "            mdl_name = 'model_tfidf.h5'       \n",
    "            model = RandomForestClassifier()\n",
    "            model.fit(X_train, y_train)\n",
    "            best_model = self.model_tuning(model, X_train, y_train)\n",
    "            with open(self.get_datadir()+mdl_name, 'wb') as file:\n",
    "                pickle.dump(best_model, file)\n",
    "        elif model_name == 'LSTM':\n",
    "            mdl_name = 'model_lstm.h5'\n",
    "            model = self.lstm_model()\n",
    "            model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "            batch_size = 64\n",
    "            n_epoch = 10\n",
    "            model.fit(X_train, y_train, batch_size=batch_size, epochs=n_epoch)\n",
    "            with open(self.get_datadir()+mdl_name, 'wb') as file:\n",
    "                pickle.dump(model, file)\n",
    "    \n",
    "    def lstm_model(self):\n",
    "        df = self.data_preprocessing()\n",
    "        X, y = (df['Reviews'].values, df['Ratings'].values)\n",
    "        tk = Tokenizer(num_words = 10000, lower=True)\n",
    "        tk.fit_on_texts(X)\n",
    "        vocabulary_size = len(tk.word_counts.keys())+1\n",
    "        max_words = 100\n",
    "        embedding_size = 50\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "        model.add(LSTM(64,dropout=0.4, recurrent_dropout=0.4,return_sequences=True))\n",
    "        model.add(LSTM(32,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        return model  \n",
    "    \n",
    "    def model_tuning(self, model, X, y):\n",
    "        param_grid =  {'n_estimators': [20, 40, 60, 80, 100],\n",
    "                       'max_features': ['auto','sqrt', 'log2'],\n",
    "                       'max_depth': [int(x) for x in np.arange(1,5)] + [None]\n",
    "                      }\n",
    "        rs_clf = RandomizedSearchCV(model, param_grid,\n",
    "                            n_jobs=-1, verbose=2, cv=5,\n",
    "                            scoring='accuracy', random_state=42)\n",
    "        model_rs = rs_clf.fit(X, y)\n",
    "        best_model = model_rs.best_estimator_\n",
    "        return best_model\n",
    "        \n",
    "    def select_model(self):\n",
    "        mdl = eval(input('Plese Select Model (1-\"TF-IDF\", 2-\"LSTM\"): '))\n",
    "        while mdl != 1 and mdl != 2:\n",
    "            print('Wrong Model Selected!')\n",
    "            mdl = eval(input('Plese Select Model (1-\"TF-IDF\", 2-\"LSTM\"): '))\n",
    "        else:\n",
    "            if mdl == 1:\n",
    "                print('Using TF-IDF...')\n",
    "                mdl_name = 'TF-IDF'\n",
    "                _, X_test, _, y_test = self.data_preparation(mdl_name)\n",
    "                model_name = 'model_tfidf.h5'\n",
    "                with open(self.get_datadir()+model_name, 'rb') as file:\n",
    "                    model = pickle.load(file)\n",
    "            elif mdl == 2:\n",
    "                print('Using LSTM...')\n",
    "                mdl_name = 'LSTM'\n",
    "                _, X_test, _, y_test = self.data_preparation(mdl_name)\n",
    "                model_name = 'model_lstm.h5'\n",
    "                with open(self.get_datadir()+model_name, 'rb') as file:\n",
    "                    model = pickle.load(file)\n",
    "        return model, mdl_name, X_test, y_test\n",
    "    \n",
    "    def result_report(self):\n",
    "        model, mdl_name, X_true, y_true = self.select_model()\n",
    "        if mdl_name == 'TF-IDF':\n",
    "            y_pred = model.predict(X_true)\n",
    "        elif mdl_name == 'LSTM':\n",
    "            y_pred = model.predict_classes(X_true)\n",
    "        print('\\033[1m{:10s}\\033[0m'.format('The classification report is as below:\\n'))\n",
    "        print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "homepage = 'https://www.tripadvisor.ca'\n",
    "url = 'https://www.tripadvisor.ca/Hotels-g155019-Toronto_Ontario-Hotels.html'\n",
    "page_no = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sna = sentiment_analysis(homepage, url, page_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sna.build_model('TF-IDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sna.build_model('LSTM')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
